{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection\n",
    "\n",
    "This notebook should include preliminary and baseline modeling.\n",
    "- Try as many different models as possible.\n",
    "- Don't worry about hyperparameter tuning or cross validation here.\n",
    "- Ideas include:\n",
    "    - linear regression\n",
    "    - support vector machines\n",
    "    - random forest\n",
    "    - xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import models and fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame loaded successfully\n"
     ]
    }
   ],
   "source": [
    "# Load the DataFrame from the pickle file\n",
    "# data = pd.read_pickle('data.pkl')\n",
    "# print(\"DataFrame loaded successfully\")\n",
    "# df = data\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pickled data\n",
    "X_train = pd.read_pickle('X_train.pkl')\n",
    "X_test = pd.read_pickle('X_test.pkl')\n",
    "y_train = pd.read_pickle('y_train.pkl')\n",
    "y_test = pd.read_pickle('y_test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null values in X_train:\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Check for null values\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNull values in X_train:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mX_train\u001b[49m\u001b[38;5;241m.\u001b[39misnull()\u001b[38;5;241m.\u001b[39msum())\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNull values in X_test:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(X_test\u001b[38;5;241m.\u001b[39misnull()\u001b[38;5;241m.\u001b[39msum())\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "# Check for null values\n",
    "print(\"Null values in X_train:\")\n",
    "print(X_train.isnull().sum())\n",
    "\n",
    "print(\"Null values in X_test:\")\n",
    "print(X_test.isnull().sum())\n",
    "\n",
    "print(\"Null values in y_train:\")\n",
    "print(y_train.isnull().sum())\n",
    "\n",
    "print(\"Null values in y_test:\")\n",
    "print(y_test.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null values in X_test after dropping rows:\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Drop rows with null values in 'city_target_encoded' in X_test\n",
    "X_test = X_test.dropna(subset=['city_target_encoded'])\n",
    "\n",
    "# Verify that null values in 'city_target_encoded' are removed\n",
    "print(\"Null values in X_test after dropping rows:\")\n",
    "print(X_test['city_target_encoded'].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary modules\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge, ElasticNet\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.isnull of       descrip_year_built  descrip_lot_sqft  descrip_sqft  garage_car_spaces  \\\n",
       "323               2005.0            4497.0        1848.0                2.0   \n",
       "409               1987.0            3206.0        3206.0                0.0   \n",
       "406               1920.0            4356.0        1086.0                0.0   \n",
       "463               1961.0           13068.0         875.0                0.0   \n",
       "1141              1971.0            6534.0        1056.0                2.0   \n",
       "...                  ...               ...           ...                ...   \n",
       "1645              1956.0            5635.0        1425.0                2.0   \n",
       "710               1910.0            9583.0        1055.0                0.0   \n",
       "440               1948.0            8581.0         864.0                1.0   \n",
       "1239              1975.0            7841.0        1634.0                0.0   \n",
       "955               1947.0            6970.0         676.0                0.0   \n",
       "\n",
       "      descrip_stories  descrip_beds  descrip_baths  property_type_condo  \\\n",
       "323               2.0           3.0            2.0                  0.0   \n",
       "409               1.0           3.0            3.0                  1.0   \n",
       "406               1.0           2.0            1.0                  0.0   \n",
       "463               0.0           3.0            1.0                  0.0   \n",
       "1141              1.0           3.0            2.0                  0.0   \n",
       "...               ...           ...            ...                  ...   \n",
       "1645              1.0           3.0            2.0                  0.0   \n",
       "710               1.0           2.0            1.0                  1.0   \n",
       "440               0.0           2.0            2.0                  0.0   \n",
       "1239              0.0           0.0            0.0                  1.0   \n",
       "955               1.0           2.0            1.0                  0.0   \n",
       "\n",
       "      property_type_land  property_type_mobile  ...  storm_shelter  \\\n",
       "323                  0.0                   0.0  ...            0.0   \n",
       "409                  0.0                   0.0  ...            0.0   \n",
       "406                  0.0                   0.0  ...            0.0   \n",
       "463                  0.0                   0.0  ...            0.0   \n",
       "1141                 0.0                   0.0  ...            0.0   \n",
       "...                  ...                   ...  ...            ...   \n",
       "1645                 0.0                   0.0  ...            0.0   \n",
       "710                  0.0                   0.0  ...            0.0   \n",
       "440                  0.0                   0.0  ...            0.0   \n",
       "1239                 0.0                   0.0  ...            0.0   \n",
       "955                  0.0                   0.0  ...            0.0   \n",
       "\n",
       "      exposed_brick  solar_power  security  pets_allowed  dining_room  \\\n",
       "323             0.0          0.0       0.0           0.0          0.0   \n",
       "409             0.0          0.0       0.0           0.0          0.0   \n",
       "406             0.0          0.0       0.0           0.0          0.0   \n",
       "463             0.0          0.0       0.0           0.0          0.0   \n",
       "1141            0.0          0.0       0.0           0.0          0.0   \n",
       "...             ...          ...       ...           ...          ...   \n",
       "1645            0.0          0.0       0.0           0.0          0.0   \n",
       "710             0.0          0.0       0.0           1.0          1.0   \n",
       "440             0.0          0.0       0.0           0.0          0.0   \n",
       "1239            0.0          0.0       0.0           0.0          0.0   \n",
       "955             0.0          0.0       0.0           0.0          0.0   \n",
       "\n",
       "      wine_cellar  days_since_sold  state_target_encoded  city_target_encoded  \n",
       "323           0.0              346          3.270593e+05         3.270593e+05  \n",
       "409           1.0              304          5.268300e+05         4.924017e+05  \n",
       "406           0.0              304          5.268300e+05         4.924017e+05  \n",
       "463           0.0              307          3.230026e+05         2.175966e+05  \n",
       "1141          0.0              321          5.035927e+05         5.035927e+05  \n",
       "...           ...              ...                   ...                  ...  \n",
       "1645          0.0              307          4.426038e+05         4.423566e+05  \n",
       "710           0.0              301          1.062229e+06         1.062229e+06  \n",
       "440           0.0              303          3.230026e+05         2.175966e+05  \n",
       "1239          0.0              406          4.025129e+05         3.844333e+05  \n",
       "955           0.0              301          6.450823e+05         6.450823e+05  \n",
       "\n",
       "[343 rows x 46 columns]>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.isnull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1404, 46)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "199      480000.0\n",
       "1382     260000.0\n",
       "801      185000.0\n",
       "1240     348900.0\n",
       "1594     524950.0\n",
       "          ...    \n",
       "1134     689900.0\n",
       "1299      95000.0\n",
       "863      250000.0\n",
       "1464     335000.0\n",
       "1130    1500000.0\n",
       "Name: descrip_sold_price, Length: 1404, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1404,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 145817530500.2917\n",
      "R-squared: 0.5065117308530277\n"
     ]
    }
   ],
   "source": [
    "# Align y_test with X_test after dropping rows with nulls in 'city_target_encoded'\n",
    "y_test = y_test[X_test.index]\n",
    "\n",
    "# Initialize and fit the linear regression model\n",
    "linear_reg = LinearRegression()\n",
    "linear_reg.fit(X_train_scaled, y_train.values)\n",
    "\n",
    "# Predict on the scaled test data\n",
    "y_pred_lr = linear_reg.predict(X_test_scaled)\n",
    "\n",
    "# Calculate performance metrics\n",
    "mse = mean_squared_error(y_test, y_pred_lr)\n",
    "r2 = r2_score(y_test, y_pred_lr)\n",
    "\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "print(f\"R-squared: {r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 301342955363.1485\n",
      "R-squared: -0.019830832078835847\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "# Initialize the Support Vector Regressor\n",
    "svm_regressor = SVR(kernel='rbf', C=100, epsilon=0.1)  # Will tune later\n",
    "\n",
    "# Fit the model on the training data\n",
    "svm_regressor.fit(X_train_scaled, y_train.values)\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred_svm = svm_regressor.predict(X_test_scaled)\n",
    "\n",
    "# Calculate performance metrics\n",
    "mse = mean_squared_error(y_test, y_pred_svm)\n",
    "r2 = r2_score(y_test, y_pred_svm)\n",
    "\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "print(f\"R-squared: {r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 118289368284.31741\n",
      "R-squared: 0.5996749127979519\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Initialize the Random Forest Regressor\n",
    "rf_regressor = RandomForestRegressor(n_estimators=100, random_state=42)  # Will tune later\n",
    "\n",
    "# Fit the model on the training data\n",
    "rf_regressor.fit(X_train_scaled, y_train.values)\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred_rf = rf_regressor.predict(X_test_scaled)\n",
    "\n",
    "# Calculate performance metrics\n",
    "mse = mean_squared_error(y_test, y_pred_rf)\n",
    "r2 = r2_score(y_test, y_pred_rf)\n",
    "\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "print(f\"R-squared: {r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 152373904869.29163\n",
      "R-squared: 0.48432308297141446\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Initialize the XGBRegressor\n",
    "xgb_regressor = XGBRegressor(objective='reg:squarederror', random_state=42)\n",
    "\n",
    "# Fit the model on the training data\n",
    "xgb_regressor.fit(X_train_scaled, y_train.values)\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred_xgb = xgb_regressor.predict(X_test_scaled)\n",
    "\n",
    "# Calculate performance metrics\n",
    "mse = mean_squared_error(y_test, y_pred_xgb)\n",
    "r2 = r2_score(y_test, y_pred_xgb)\n",
    "\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "print(f\"R-squared: {r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider what metrics you want to use to evaluate success.\n",
    "- If you think about mean squared error, can we actually relate to the amount of error?\n",
    "- Try root mean squared error so that error is closer to the original units (dollars)\n",
    "- What does RMSE do to outliers?\n",
    "- Is mean absolute error a good metric for this problem?\n",
    "- What about R^2? Adjusted R^2?\n",
    "- Briefly describe your reasons for picking the metrics you use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gather evaluation metrics and compare results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression Metrics:\n",
      "Mean Squared Error (MSE): 145817530500.2917\n",
      "Root Mean Squared Error (RMSE): 381860.61658711504\n",
      "Mean Absolute Error (MAE): 169440.57358138394\n",
      "R-squared (R²): 0.5065117308530277\n",
      "Adjusted R-squared: 0.4298209863234306\n",
      "\n",
      "Support Vector Machine Metrics:\n",
      "Mean Squared Error (MSE): 301342955363.1485\n",
      "Root Mean Squared Error (RMSE): 548947.1334865941\n",
      "Mean Absolute Error (MAE): 240273.54469297137\n",
      "R-squared (R²): -0.019830832078835847\n",
      "Adjusted R-squared: -0.17831805598297934\n",
      "\n",
      "Random Forest Metrics:\n",
      "Mean Squared Error (MSE): 118289368284.31741\n",
      "Root Mean Squared Error (RMSE): 343932.21466492116\n",
      "Mean Absolute Error (MAE): 132034.9503377065\n",
      "R-squared (R²): 0.5996749127979519\n",
      "Adjusted R-squared: 0.5374622303273633\n",
      "\n",
      "XGBoost Metrics:\n",
      "Mean Squared Error (MSE): 152373904869.29163\n",
      "Root Mean Squared Error (RMSE): 390351.0021369122\n",
      "Mean Absolute Error (MAE): 141338.50884600493\n",
      "R-squared (R²): 0.48432308297141446\n",
      "Adjusted R-squared: 0.4041841026223775\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Define a function to calculate metrics\n",
    "def calculate_metrics(y_test, y_pred, n, k):\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    adj_r2 = 1 - (1 - r2) * ((n - 1) / (n - k - 1))\n",
    "    \n",
    "    print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "    print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
    "    print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "    print(f\"R-squared (R²): {r2}\")\n",
    "    print(f\"Adjusted R-squared: {adj_r2}\")\n",
    "\n",
    "# Number of samples (n) and number of features (k)\n",
    "n = len(y_test)\n",
    "k = X_train.shape[1]\n",
    "\n",
    "# Linear Regression\n",
    "print(\"Linear Regression Metrics:\")\n",
    "calculate_metrics(y_test, y_pred_lr, n, k)\n",
    "\n",
    "# Support Vector Machine\n",
    "print(\"\\nSupport Vector Machine Metrics:\")\n",
    "calculate_metrics(y_test, y_pred_svm, n, k)\n",
    "\n",
    "# Random Forest\n",
    "print(\"\\nRandom Forest Metrics:\")\n",
    "calculate_metrics(y_test, y_pred_rf, n, k)\n",
    "\n",
    "# XGBoost\n",
    "print(\"\\nXGBoost Metrics:\")\n",
    "calculate_metrics(y_test, y_pred_xgb, n, k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection - STRETCH\n",
    "\n",
    "> **This step doesn't need to be part of your Minimum Viable Product (MVP), but its recommended you complete it if you have time!**\n",
    "\n",
    "Even with all the preprocessing we did in Notebook 1, you probably still have a lot of features. Are they all important for prediction?\n",
    "\n",
    "Investigate some feature selection algorithms (Lasso, RFE, Forward/Backward Selection)\n",
    "- Perform feature selection to get a reduced subset of your original features\n",
    "- Refit your models with this reduced dimensionality - how does performance change on your chosen metrics?\n",
    "- Based on this, should you include feature selection in your final pipeline? Explain\n",
    "\n",
    "Remember, feature selection often doesn't directly improve performance, but if performance remains the same, a simpler model is often preferrable. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform feature selection \n",
    "# refit models\n",
    "# gather evaluation metrics and compare to the previous step (full feature set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso Selected Features: Index(['descrip_year_built', 'descrip_lot_sqft', 'descrip_sqft',\n",
      "       'garage_car_spaces', 'descrip_stories', 'descrip_beds', 'descrip_baths',\n",
      "       'property_type_condo', 'property_type_land', 'property_type_mobile',\n",
      "       'property_type_multi_family', 'property_type_other_unknown',\n",
      "       'property_type_single_family', 'property_type_townhouse', 'has_parking',\n",
      "       'heating', 'porch', 'laundry_facilities', 'notable_kitchen',\n",
      "       'notable_ceiling', 'recently_updated', 'multimedia_room',\n",
      "       'enclosed_yard', 'cul_de_sac', 'family_room', 'hardwood_floors',\n",
      "       'basement', 'rental_property', 'furniture', 'private_courtyard',\n",
      "       'central_air', 'dishwasher', 'fireplace', 'den_or_office',\n",
      "       'smart_homes', 'guest_parking', 'storm_shelter', 'exposed_brick',\n",
      "       'solar_power', 'security', 'pets_allowed', 'dining_room', 'wine_cellar',\n",
      "       'days_since_sold', 'state_target_encoded', 'city_target_encoded'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mahmu\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.600e+10, tolerance: 2.378e+10\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Ensure the data is scaled\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Fit Lasso\n",
    "lasso = Lasso(alpha=0.1, max_iter=10000)  # Adjust alpha as needed\n",
    "lasso.fit(X_train_scaled, y_train.values)\n",
    "\n",
    "# Get the selected features\n",
    "selected_features = X_train.columns[(lasso.coef_ != 0)]\n",
    "print(\"Lasso Selected Features:\", selected_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RFE Selected Features: Index(['descrip_year_built', 'descrip_lot_sqft', 'descrip_sqft',\n",
      "       'descrip_beds', 'descrip_baths', 'property_type_condo',\n",
      "       'property_type_single_family', 'pets_allowed', 'state_target_encoded',\n",
      "       'city_target_encoded'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "# Choose a model for RFE\n",
    "model = LinearRegression()\n",
    "rfe = RFE(estimator=model, n_features_to_select=10)  # Adjust number of features as needed\n",
    "rfe.fit(X_train_scaled, y_train.values)\n",
    "\n",
    "# Get selected features\n",
    "selected_features = X_train.columns[rfe.support_]\n",
    "print(\"RFE Selected Features:\", selected_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Forward Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 22\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m selected_features\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Run forward selection\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m selected_features_forward \u001b[38;5;241m=\u001b[39m \u001b[43mforward_selection\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_scaled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mForward Selection Selected Features:\u001b[39m\u001b[38;5;124m\"\u001b[39m, selected_features_forward)\n",
      "Cell \u001b[1;32mIn[32], line 11\u001b[0m, in \u001b[0;36mforward_selection\u001b[1;34m(X, y, significance_level)\u001b[0m\n\u001b[0;32m      9\u001b[0m new_pval \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mSeries(index\u001b[38;5;241m=\u001b[39mremaining_features)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m new_column \u001b[38;5;129;01min\u001b[39;00m remaining_features:\n\u001b[1;32m---> 11\u001b[0m     model \u001b[38;5;241m=\u001b[39m sm\u001b[38;5;241m.\u001b[39mOLS(y, sm\u001b[38;5;241m.\u001b[39madd_constant(\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43mselected_features\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mnew_column\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m))\u001b[38;5;241m.\u001b[39mfit()\n\u001b[0;32m     12\u001b[0m     new_pval[new_column] \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpvalues[new_column]\n\u001b[0;32m     13\u001b[0m min_p_value \u001b[38;5;241m=\u001b[39m new_pval\u001b[38;5;241m.\u001b[39mmin()\n",
      "\u001b[1;31mIndexError\u001b[0m: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "import pandas as pd\n",
    "\n",
    "def forward_selection(X, y, significance_level=0.05):\n",
    "    initial_features = X_train.columns.tolist()\n",
    "    selected_features = []\n",
    "    while len(initial_features) > 0:\n",
    "        remaining_features = list(set(initial_features) - set(selected_features))\n",
    "        new_pval = pd.Series(index=remaining_features)\n",
    "        for new_column in remaining_features:\n",
    "            model = sm.OLS(y, sm.add_constant(X[selected_features + [new_column]])).fit()\n",
    "            new_pval[new_column] = model.pvalues[new_column]\n",
    "        min_p_value = new_pval.min()\n",
    "        if min_p_value < significance_level:\n",
    "            best_feature = new_pval.idxmin()\n",
    "            selected_features.append(best_feature)\n",
    "        else:\n",
    "            break\n",
    "    return selected_features\n",
    "\n",
    "# Run forward selection\n",
    "selected_features_forward = forward_selection(X_train_scaled, y_train.values)\n",
    "print(\"Forward Selection Selected Features:\", selected_features_forward)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Backward Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backward Selection Selected Features: ['year', 'km_driven', 'kmpl', 'engine_cc', 'power_bhp', 'seats']\n"
     ]
    }
   ],
   "source": [
    "def backward_selection(X, y, significance_level=0.05):\n",
    "    features = X.columns.tolist()\n",
    "    while len(features) > 0:\n",
    "        model = sm.OLS(y, sm.add_constant(X[features])).fit()\n",
    "        p_values = model.pvalues.iloc[1:]  # Exclude intercept p-value\n",
    "        max_p_value = p_values.max()\n",
    "        if max_p_value >= significance_level:\n",
    "            excluded_feature = p_values.idxmax()\n",
    "            features.remove(excluded_feature)\n",
    "        else:\n",
    "            break\n",
    "    return features\n",
    "\n",
    "# Run backward selection\n",
    "selected_features_backward = backward_selection(X, y)\n",
    "print(\"Backward Selection Selected Features:\", selected_features_backward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
